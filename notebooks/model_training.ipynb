{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:58:28.982288Z",
     "iopub.status.busy": "2025-07-17T09:58:28.981764Z",
     "iopub.status.idle": "2025-07-17T10:01:58.187638Z",
     "shell.execute_reply": "2025-07-17T10:01:58.186682Z",
     "shell.execute_reply.started": "2025-07-17T09:58:28.982258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install timm opencv-python-headless scikit-learn \"numpy<2\" --quiet --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:01:58.189555Z",
     "iopub.status.busy": "2025-07-17T10:01:58.189295Z",
     "iopub.status.idle": "2025-07-17T10:02:06.070098Z",
     "shell.execute_reply": "2025-07-17T10:02:06.069313Z",
     "shell.execute_reply.started": "2025-07-17T10:01:58.189532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "import timm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:02:06.071367Z",
     "iopub.status.busy": "2025-07-17T10:02:06.070858Z",
     "iopub.status.idle": "2025-07-17T10:02:06.133681Z",
     "shell.execute_reply": "2025-07-17T10:02:06.132679Z",
     "shell.execute_reply.started": "2025-07-17T10:02:06.071347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_PATH = '/kaggle/input/crop-diseases-2/Dataset for Crop Pest and Disease Detection/CCMT Dataset-Augmented'\n",
    "    MODEL_NAME = 'mobilenetv3_large_100'\n",
    "    NUM_CLASSES = 22\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 2e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    EPOCHS = 10\n",
    "    N_FOLDS = 5\n",
    "    EARLY_STOPPING_PATIENCE = 5\n",
    "    SCHEDULER_PATIENCE = 3\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    MIXUP_ALPHA = 0.3\n",
    "    OUTPUT_DIR = '/kaggle/working'\n",
    "    MODELS_DIR = f'{OUTPUT_DIR}/models'\n",
    "    PLOTS_DIR = f'{OUTPUT_DIR}/plots'\n",
    "    \n",
    "    \n",
    "    GRADIENT_ACCUMULATION_STEPS = 2\n",
    "    USE_MIXED_PRECISION = True\n",
    "    MAX_GRAD_NORM = 1.0\n",
    "\n",
    "os.makedirs(Config.MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(Config.PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Enable memory optimization\n",
    "if Config.USE_MIXED_PRECISION:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    scaler = GradScaler()\n",
    "\n",
    "print(f\"Using device: {Config.DEVICE}\")\n",
    "print(f\"Model: {Config.MODEL_NAME}\")\n",
    "print(f\"Image size: {Config.IMG_SIZE}\")\n",
    "print(f\"Batch size: {Config.BATCH_SIZE}\")\n",
    "print(f\"Mixed precision: {Config.USE_MIXED_PRECISION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:02:06.135156Z",
     "iopub.status.busy": "2025-07-17T10:02:06.134741Z",
     "iopub.status.idle": "2025-07-17T10:02:19.134506Z",
     "shell.execute_reply": "2025-07-17T10:02:19.133372Z",
     "shell.execute_reply.started": "2025-07-17T10:02:06.135125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataframes(base_path):\n",
    "    crops = ['Cashew', 'Cassava', 'Maize', 'Tomato']\n",
    "    all_train_files, all_test_files, class_to_idx = [], [], {}\n",
    "    current_idx = 0\n",
    "    \n",
    "    print(\"Scanning directories and cleaning names...\")\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"ERROR: Base path not found at {base_path}.\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), {}, {}\n",
    "\n",
    "    for crop in crops:\n",
    "        for phase, file_list in [('train_set', all_train_files), ('test_set', all_test_files)]:\n",
    "            crop_path = os.path.join(base_path, crop, phase)\n",
    "            if not os.path.exists(crop_path):\n",
    "                continue\n",
    "            \n",
    "            for disease_folder in os.listdir(crop_path):\n",
    "                if not os.path.isdir(os.path.join(crop_path, disease_folder)):\n",
    "                    continue\n",
    "                \n",
    "                clean_disease_name = re.sub(r'\\d+$', '', disease_folder).strip()\n",
    "                composite_class_name = f\"{crop}_{clean_disease_name}\"\n",
    "                \n",
    "                if composite_class_name not in class_to_idx:\n",
    "                    if phase == 'train_set':\n",
    "                        class_to_idx[composite_class_name] = current_idx\n",
    "                        current_idx += 1\n",
    "                    else:\n",
    "                        # Ensure test classes are also in train classes\n",
    "                        if composite_class_name in class_to_idx:\n",
    "                             pass\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                class_idx = class_to_idx.get(composite_class_name)\n",
    "                if class_idx is None: continue\n",
    "                \n",
    "                disease_path = os.path.join(crop_path, disease_folder)\n",
    "                \n",
    "                for filename in os.listdir(disease_path):\n",
    "                    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        file_list.append({\n",
    "                            'filepath': os.path.join(disease_path, filename),\n",
    "                            'class_name': composite_class_name,\n",
    "                            'class_idx': class_idx\n",
    "                        })\n",
    "\n",
    "    df_train = pd.DataFrame(all_train_files).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    df_test = pd.DataFrame(all_test_files).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "    \n",
    "   \n",
    "    df_test = df_test[df_test['class_idx'].isin(df_train['class_idx'].unique())].reset_index(drop=True)\n",
    "\n",
    "    Config.NUM_CLASSES = len(class_to_idx)\n",
    "    print(f\"\\nFound {Config.NUM_CLASSES} unique classes after cleaning.\")\n",
    "    print(f\"Total training images: {len(df_train)}\")\n",
    "    print(f\"Total testing images: {len(df_test)}\")\n",
    "    \n",
    "    return df_train, df_test, class_to_idx, idx_to_class\n",
    "\n",
    "df_train, df_test, class_to_idx, idx_to_class = prepare_dataframes(Config.DATA_PATH)\n",
    "if class_to_idx:\n",
    "    with open(f'{Config.OUTPUT_DIR}/class_mappings.json', 'w') as f:\n",
    "        json.dump({'class_to_idx': class_to_idx, 'idx_to_class': idx_to_class}, f)\n",
    "    print(\"\\nClass Distribution in Training Data:\")\n",
    "    print(df_train['class_name'].value_counts())\n",
    "else:\n",
    "    df_train = pd.DataFrame()\n",
    "\n",
    "\n",
    "class LightweightAugmentation:\n",
    "    def __init__(self, img_size=224):\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        if random.random() < 0.5:\n",
    "            image = TF.hflip(image)\n",
    "        if random.random() < 0.3:\n",
    "            image = TF.vflip(image)\n",
    "        if random.random() < 0.4:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            image = TF.rotate(image, angle)\n",
    "        image = TF.resize(image, int(self.img_size * 1.1))\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, (self.img_size, self.img_size))\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        return image\n",
    "\n",
    "def get_transforms(phase='train'):\n",
    "    if phase == 'train':\n",
    "        return transforms.Compose([\n",
    "            LightweightAugmentation(Config.IMG_SIZE),\n",
    "            transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.2, scale=(0.02, 0.08))\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Lambda(lambda x: Image.fromarray(x) if isinstance(x, np.ndarray) else x),\n",
    "            transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:02:19.138215Z",
     "iopub.status.busy": "2025-07-17T10:02:19.137862Z",
     "iopub.status.idle": "2025-07-17T10:02:19.146087Z",
     "shell.execute_reply": "2025-07-17T10:02:19.145130Z",
     "shell.execute_reply.started": "2025-07-17T10:02:19.138181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CropDiseaseDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = torch.tensor(row['class_idx'], dtype=torch.long)\n",
    "        image = cv2.imread(row['filepath'])\n",
    "        if image is None:\n",
    "            image = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:02:19.147739Z",
     "iopub.status.busy": "2025-07-17T10:02:19.147421Z",
     "iopub.status.idle": "2025-07-17T10:02:19.167781Z",
     "shell.execute_reply": "2025-07-17T10:02:19.167057Z",
     "shell.execute_reply.started": "2025-07-17T10:02:19.147712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MobileNetV3CropModel(nn.Module):\n",
    "    def __init__(self, model_name=Config.MODEL_NAME, num_classes=Config.NUM_CLASSES, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        num_features = self.backbone.num_features\n",
    "        self.backbone.reset_classifier(0)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(num_features),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(num_features, num_features // 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(num_features // 4),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(num_features // 4, num_classes)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone.forward_features(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "        \n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience, self.verbose, self.delta = patience, verbose, delta\n",
    "        self.counter, self.best_score, self.early_stop = 0, None, False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose: print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose: print(f'Val loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        self.best_weights = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        if self.best_weights:\n",
    "            model.load_state_dict({k: v.to(Config.DEVICE) for k, v in self.best_weights.items()})\n",
    "        return model\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, num_classes, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.num_classes, self.smoothing = num_classes, smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.num_classes - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=-1))\n",
    "\n",
    "def mixup_data(x, y, alpha=0.3):\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:02:19.169909Z",
     "iopub.status.busy": "2025-07-17T10:02:19.168823Z",
     "iopub.status.idle": "2025-07-17T10:02:19.191179Z",
     "shell.execute_reply": "2025-07-17T10:02:19.190424Z",
     "shell.execute_reply.started": "2025-07-17T10:02:19.169878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(loader, desc='[Train]')):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        \n",
    "        # Use mixed precision if available\n",
    "        if Config.USE_MIXED_PRECISION and scaler is not None:\n",
    "            with autocast():\n",
    "                # Apply mixup occasionally\n",
    "                if np.random.rand() < 0.3 and Config.MIXUP_ALPHA > 0:\n",
    "                    mixed_data, y_a, y_b, lam = mixup_data(data, target, Config.MIXUP_ALPHA)\n",
    "                    output = model(mixed_data)\n",
    "                    loss = mixup_criterion(criterion, output, y_a, y_b, lam)\n",
    "                else:\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                \n",
    "                # Normalize loss by gradient accumulation steps\n",
    "                loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient accumulation\n",
    "            if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        else:\n",
    "            # Regular training without mixed precision\n",
    "            if np.random.rand() < 0.3 and Config.MIXUP_ALPHA > 0:\n",
    "                mixed_data, y_a, y_b, lam = mixup_data(data, target, Config.MIXUP_ALPHA)\n",
    "                output = model(mixed_data)\n",
    "                loss = mixup_criterion(criterion, output, y_a, y_b, lam)\n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n",
    "            loss.backward()\n",
    "            \n",
    "            if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item() * Config.GRADIENT_ACCUMULATION_STEPS * data.size(0)\n",
    "        total_samples += target.size(0)\n",
    "        \n",
    "        # Calculate accuracy (only for non-mixup batches)\n",
    "        if np.random.rand() >= 0.3 or Config.MIXUP_ALPHA <= 0:\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Clear cache periodically\n",
    "        if batch_idx % 20 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = (total_correct / total_samples) * 100\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(loader, desc='[Val]')):\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            \n",
    "            if Config.USE_MIXED_PRECISION:\n",
    "                with autocast():\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            total_samples += target.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Clear cache periodically\n",
    "            if batch_idx % 20 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = (total_correct / total_samples) * 100\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:02:19.192582Z",
     "iopub.status.busy": "2025-07-17T10:02:19.192022Z",
     "iopub.status.idle": "2025-07-17T10:02:19.209803Z",
     "shell.execute_reply": "2025-07-17T10:02:19.209039Z",
     "shell.execute_reply.started": "2025-07-17T10:02:19.192556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_kfold(df_train, n_folds=Config.N_FOLDS):\n",
    "    if df_train.empty:\n",
    "        print(\"Training df empty. Halting.\")\n",
    "        return [], None\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    results = []\n",
    "    oof_preds = np.zeros((len(df_train), Config.NUM_CLASSES))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df_train, df_train['class_idx'])):\n",
    "        print(f\"\\n{'='*20} FOLD {fold+1}/{n_folds} {'='*20}\")\n",
    "        \n",
    "        # Clear memory before each fold\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        train_df = df_train.iloc[train_idx]\n",
    "        val_df = df_train.iloc[val_idx]\n",
    "        \n",
    "        # Data loaders with memory optimization\n",
    "        train_loader = DataLoader(\n",
    "            CropDiseaseDataset(train_df, get_transforms('train')),\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            CropDiseaseDataset(val_df, get_transforms('val')),\n",
    "            batch_size=Config.BATCH_SIZE * 2,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        model = MobileNetV3CropModel().to(Config.DEVICE)\n",
    "        \n",
    "        # Optimizer with different learning rates for backbone and classifier\n",
    "        backbone_params = [p for name, p in model.named_parameters() if 'backbone' in name]\n",
    "        classifier_params = [p for name, p in model.named_parameters() if 'classifier' in name]\n",
    "        \n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': Config.LEARNING_RATE * 0.1},  # Lower LR for pretrained backbone\n",
    "            {'params': classifier_params, 'lr': Config.LEARNING_RATE}\n",
    "        ], weight_decay=Config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=5, T_mult=2, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        # Loss function with label smoothing\n",
    "        criterion = LabelSmoothingLoss(Config.NUM_CLASSES, smoothing=0.1).to(Config.DEVICE)\n",
    "        early_stopping = EarlyStopping(patience=Config.EARLY_STOPPING_PATIENCE, verbose=True)\n",
    "        \n",
    "        # Mixed precision scaler\n",
    "        fold_scaler = GradScaler() if Config.USE_MIXED_PRECISION else None\n",
    "        \n",
    "        history = defaultdict(list)\n",
    "        \n",
    "        for epoch in range(Config.EPOCHS):\n",
    "            print(f\"Epoch {epoch+1}/{Config.EPOCHS}\")\n",
    "            \n",
    "            train_loss, train_acc = train_one_epoch(\n",
    "                model, train_loader, criterion, optimizer, Config.DEVICE, fold_scaler\n",
    "            )\n",
    "            val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, Config.DEVICE)\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            \n",
    "            scheduler.step()\n",
    "            early_stopping(val_loss, model)\n",
    "            \n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best weights and save model\n",
    "        model = early_stopping.load_best_weights(model)\n",
    "        torch.save(model.state_dict(), f'{Config.MODELS_DIR}/mobilenet_model_fold_{fold+1}.pth')\n",
    "        \n",
    "        \n",
    "        fold_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, _) in enumerate(tqdm(val_loader, desc=\"OOF Preds\")):\n",
    "                data = data.to(Config.DEVICE, non_blocking=True)\n",
    "                \n",
    "                if Config.USE_MIXED_PRECISION:\n",
    "                    with autocast():\n",
    "                        output = model(data)\n",
    "                else:\n",
    "                    output = model(data)\n",
    "                \n",
    "                probabilities = F.softmax(output, dim=1)\n",
    "                fold_preds.append(probabilities.cpu().numpy())\n",
    "                \n",
    "                # Clear cache\n",
    "                if batch_idx % 10 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        oof_preds[val_idx] = np.concatenate(fold_preds)\n",
    "        \n",
    "        results.append({'history': history})\n",
    "        print(f\"Fold {fold+1} Best Val Acc: {np.max(history['val_acc']):.2f}%\")\n",
    "        \n",
    "        # Clean up memory\n",
    "        del model, train_loader, val_loader, optimizer, scheduler, criterion\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    cv_mean_acc = np.mean([np.max(fold_result['history']['val_acc']) for fold_result in results])\n",
    "    print(f\"\\nCV Mean Best Acc: {cv_mean_acc:.2f}%\")\n",
    "    \n",
    "    # Save OOF predictions\n",
    "    np.save(f'{Config.OUTPUT_DIR}/oof_predictions_mobilenet.npy', oof_preds)\n",
    "    \n",
    "    return results, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-17T10:12:41.288Z",
     "iopub.execute_input": "2025-07-17T10:02:19.210795Z",
     "iopub.status.busy": "2025-07-17T10:02:19.210560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fold_results, oof_predictions = train_kfold(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-17T10:12:41.289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_history(fold_results):\n",
    "    if not fold_results:\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    for i, result in enumerate(fold_results):\n",
    "        history = result['history']\n",
    "        axes[0].plot(history['val_loss'], label=f'Fold {i+1} Val Loss')\n",
    "        axes[1].plot(history['val_acc'], label=f'Fold {i+1} Val Acc')\n",
    "    \n",
    "    axes[0].set_title('Validation Loss - MobileNetV3')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    axes[1].set_title('Validation Accuracy - MobileNetV3')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{Config.PLOTS_DIR}/mobilenet_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_oof_predictions(oof_preds, df, idx_to_class_map):\n",
    "    if oof_preds is None or df.empty or not idx_to_class_map:\n",
    "        return\n",
    "    \n",
    "    true_labels = df['class_idx'].values\n",
    "    pred_labels = np.argmax(oof_preds, axis=1)\n",
    "    \n",
    "    target_names = [idx_to_class_map[i] for i in sorted(idx_to_class_map.keys())]\n",
    "    \n",
    "    oof_accuracy = accuracy_score(true_labels, pred_labels) * 100\n",
    "    print(f\"\\nOOF Accuracy (MobileNetV3): {oof_accuracy:.2f}%\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, yticklabels=target_names, cbar=False)\n",
    "    plt.title('MobileNetV3 Out-of-Fold Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{Config.PLOTS_DIR}/mobilenet_oof_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot results\n",
    "plot_training_history(fold_results)\n",
    "analyze_oof_predictions(oof_predictions, df_train, idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-17T10:12:41.290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MobileNetEnsemble:\n",
    "    def __init__(self, model_paths, device):\n",
    "        self.models = []\n",
    "        self.device = device\n",
    "        \n",
    "        for path in model_paths:\n",
    "            if os.path.exists(path):\n",
    "                model = self.load_model(path, device)\n",
    "                self.models.append(model)\n",
    "        \n",
    "        print(f\"Loaded {len(self.models)} MobileNetV3 models for ensemble.\")\n",
    "    \n",
    "    def load_model(self, path, device):\n",
    "        model = MobileNetV3CropModel(pretrained=False)\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "    def predict(self, loader):\n",
    "        if not self.models:\n",
    "            return None\n",
    "        \n",
    "        all_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, _) in enumerate(tqdm(loader, desc=\"Ensemble Inference\")):\n",
    "                data = data.to(self.device, non_blocking=True)\n",
    "                \n",
    "                # Get predictions from all models\n",
    "                batch_predictions = []\n",
    "                for model in self.models:\n",
    "                    if Config.USE_MIXED_PRECISION:\n",
    "                        with autocast():\n",
    "                            output = model(data)\n",
    "                    else:\n",
    "                        output = model(data)\n",
    "                    \n",
    "                    probabilities = F.softmax(output, dim=1)\n",
    "                    batch_predictions.append(probabilities)\n",
    "                \n",
    "                # Average predictions\n",
    "                ensemble_pred = torch.stack(batch_predictions).mean(dim=0)\n",
    "                all_predictions.append(ensemble_pred.cpu().numpy())\n",
    "                \n",
    "                # Clear cache\n",
    "                if batch_idx % 10 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        return np.concatenate(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-17T10:12:41.291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_paths = [f'{Config.MODELS_DIR}/mobilenet_model_fold_{i+1}.pth' for i in range(Config.N_FOLDS)]\n",
    "ensemble_model = MobileNetEnsemble(model_paths, Config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-17T10:12:41.292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_test_set(df_test, ensemble, idx_to_class_map):\n",
    "    if df_test.empty or not hasattr(ensemble, 'models') or not ensemble.models or not idx_to_class_map:\n",
    "        print(\"Skipping test evaluation - missing data or models.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluating MobileNetV3 on Test Set {'='*20}\")\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        CropDiseaseDataset(df_test, get_transforms('val')),\n",
    "        batch_size=Config.BATCH_SIZE * 2, # Use larger batch for inference\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_predictions = ensemble.predict(test_loader)\n",
    "    \n",
    "    if test_predictions is not None:\n",
    "        true_labels = df_test['class_idx'].values\n",
    "        pred_labels = np.argmax(test_predictions, axis=1)\n",
    "        \n",
    "        target_names = [idx_to_class_map[i] for i in sorted(idx_to_class_map.keys())]\n",
    "        \n",
    "        test_accuracy = accuracy_score(true_labels, pred_labels) * 100\n",
    "        print(f\"\\nFinal Test Set Accuracy (Ensemble): {test_accuracy:.2f}%\")\n",
    "        \n",
    "        print(\"\\nClassification Report (Test Set):\")\n",
    "        print(classification_report(true_labels, pred_labels, target_names=target_names, digits=3))\n",
    "        \n",
    "        # Confusion Matrix for Test Set\n",
    "        cm = confusion_matrix(true_labels, pred_labels)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "                    xticklabels=target_names, yticklabels=target_names, cbar=False)\n",
    "        plt.title('MobileNetV3 Test Set Confusion Matrix (Ensemble)')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{Config.PLOTS_DIR}/mobilenet_test_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "evaluate_test_set(df_test, ensemble_model, idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-17T10:12:41.293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "class PredictionPipeline:\n",
    "    def __init__(self, model, transforms, idx_to_class):\n",
    "        # For deployment, it's best practice to force the model to CPU\n",
    "        self.device = torch.device('cpu')\n",
    "        self.model = model\n",
    "       \n",
    "        for m in self.model.models:\n",
    "            m.to(self.device)\n",
    "            m.eval()\n",
    "        self.transforms = transforms\n",
    "        self.idx_to_class = idx_to_class\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Takes the path to an image, preprocesses it, and returns the predicted class and confidence.\n",
    "        \"\"\"\n",
    "        # Load and preprocess image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply transforms\n",
    "        transformed_image = self.transforms(image)\n",
    "        # Add batch dimension and move to CPU\n",
    "        tensor = transformed_image.unsqueeze(0).to(self.device)\n",
    "\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            # Get raw logits from each model in the ensemble\n",
    "            batch_predictions = [m(tensor) for m in self.model.models]\n",
    "            \n",
    "            ensemble_pred = torch.stack(batch_predictions).mean(dim=0)\n",
    "            probabilities = F.softmax(ensemble_pred, dim=1)\n",
    "        \n",
    "        # 4. Get top prediction and confidence\n",
    "        confidence, pred_idx = torch.max(probabilities, 1)\n",
    "        pred_idx = pred_idx.item()\n",
    "        \n",
    "        # 5. Map index to class name\n",
    "        predicted_class = self.idx_to_class.get(pred_idx, \"Unknown Class\")\n",
    "        \n",
    "        return predicted_class, confidence.item() * 100\n",
    "\n",
    "inference_transforms = get_transforms('val')\n",
    "\n",
    "int_idx_to_class = {int(k): v for k, v in idx_to_class.items()}\n",
    "\n",
    "\n",
    "ensemble_model_cpu = MobileNetEnsemble(model_paths, device=torch.device('cpu'))\n",
    "\n",
    "\n",
    "deployment_pipeline = PredictionPipeline(\n",
    "    model=ensemble_model_cpu,\n",
    "    transforms=inference_transforms,\n",
    "    idx_to_class=int_idx_to_class\n",
    ")\n",
    "\n",
    "pipeline_path = f'{Config.OUTPUT_DIR}/mobilenet_deployment_pipeline.joblib'\n",
    "joblib.dump(deployment_pipeline, pipeline_path)\n",
    "\n",
    "print(f\"\\nâœ… Deployment pipeline saved successfully to: {pipeline_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-17T10:12:41.294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"--- Testing the saved deployment pipeline ---\")\n",
    "\n",
    "\n",
    "try:\n",
    "    loaded_pipeline = joblib.load(pipeline_path)\n",
    "    print(\"Pipeline loaded successfully.\")\n",
    "\n",
    "   \n",
    "    if not df_test.empty:\n",
    "        sample_row = df_test.sample(1).iloc[0]\n",
    "        sample_image_path = sample_row['filepath']\n",
    "        true_label = sample_row['class_name']\n",
    "        \n",
    "        print(f\"\\nTesting with image: {sample_image_path}\")\n",
    "        print(f\"True Label: {true_label}\")\n",
    "\n",
    "        # Make a prediction\n",
    "        predicted_class, confidence = loaded_pipeline.predict(sample_image_path)\n",
    "        \n",
    "        # Display image\n",
    "        img = Image.open(sample_image_path)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Predicted: {predicted_class} ({confidence:.2f}%)\\nTrue: {true_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\nPredicted Disease: {predicted_class}\")\n",
    "        print(f\"Confidence: {confidence:.2f}%\")\n",
    "    else:\n",
    "        print(\"Test dataframe is empty, cannot demonstrate prediction.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find the pipeline file at {pipeline_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7870299,
     "sourceId": 12474370,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
